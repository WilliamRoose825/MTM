from __future__ import annotations

"""Streamlit page: Analyse de co-occurrence et clustering d'ingr√©dients.

Cette page utilise une matrice de co-occurrence PR√âCALCUL√âE pour optimiser les performances.
La matrice 300x300 est g√©n√©r√©e √† froid par utils/preprocess_ingredients_matrix.py.
"""

from dataclasses import dataclass
from pathlib import Path
from typing import Optional

import numpy as np
import pandas as pd
import plotly.graph_objects as go
import streamlit as st
from sklearn.cluster import KMeans
from sklearn.manifold import TSNE

from core.logger import get_logger


@dataclass
class IngredientsClusteringConfig:
    """Configuration pour l'analyse de clustering d'ingr√©dients.

    Attributes:
        matrix_path: Chemin vers la matrice de co-occurrence pr√©calcul√©e.
        ingredients_list_path: Chemin vers la liste des ingr√©dients.
        n_ingredients: Nombre d'ingr√©dients √† analyser (de la matrice 300x300).
        n_clusters: Nombre de clusters √† cr√©er avec K-means.
        tsne_perplexity: Param√®tre de perplexit√© pour la visualisation t-SNE.
    """

    matrix_path: Path = Path("data/ingredients_cooccurrence_matrix.csv")
    ingredients_list_path: Path = Path("data/ingredients_list.csv")
    n_ingredients: int = 40
    n_clusters: int = 4
    tsne_perplexity: int = 30


class IngredientsClusteringPage:
    """Page Streamlit pour l'analyse de clustering des ingr√©dients.

    Cette classe charge une matrice de co-occurrence PR√âCALCUL√âE et effectue
    le clustering et la visualisation en temps r√©el.

    Attributes:
        matrix_path: Chemin vers la matrice de co-occurrence pr√©calcul√©e.
        ingredients_list_path: Chemin vers la liste des ingr√©dients.
        logger: Instance du logger pour le suivi des op√©rations.
    """

    def __init__(
        self,
        matrix_path: str = "data/ingredients_cooccurrence_matrix.csv",
        ingredients_list_path: str = "data/ingredients_list.csv",
    ) -> None:
        """Initialise la page de clustering d'ingr√©dients.

        Args:
            matrix_path: Chemin vers la matrice de co-occurrence pr√©calcul√©e (300x300).
            ingredients_list_path: Chemin vers la liste des 300 ingr√©dients avec fr√©quences.
        """
        self.matrix_path = Path(matrix_path)
        self.ingredients_list_path = Path(ingredients_list_path)
        self.logger = get_logger()
        self.logger.info("Initializing IngredientsClusteringPage with precomputed matrix")

    @st.cache_data(ttl=None, show_spinner="Chargement de la matrice pr√©calcul√©e...")
    def _load_cooccurrence_matrix(_self) -> Optional[tuple[pd.DataFrame, pd.DataFrame]]:
        """Charge et sanitise la matrice de co-occurrence + liste d'ingr√©dients.

        Sanitation appliqu√©e:
        - Strip espaces
        - D√©tection mismatch index/colonnes
        - For√ßage de la sym√©trie (colonnes = index) si n√©cessaire
        - Suppression doublons √©ventuels

        Returns:
            Tuple (matrice 300x300 nettoy√©e, liste des ingr√©dients) si succ√®s, None sinon.
        """
        try:
            if not _self.matrix_path.exists():
                st.error(f"‚ùå Matrice introuvable: {_self.matrix_path}")
                st.info("üí° Ex√©cutez d'abord: `uv run python -m utils.preprocess_ingredients_matrix`")
                st.stop()
                return None

            cooc_matrix = pd.read_csv(_self.matrix_path, index_col=0)
            _self.logger.info(f"‚úÖ Matrice charg√©e brute: {cooc_matrix.shape}")

            # Validation de forme: la matrice doit √™tre carr√©e et <= 400x400
            if cooc_matrix.shape[0] != cooc_matrix.shape[1] or cooc_matrix.shape[0] < 10:
                _self.logger.error(
                    "‚ùå Le fichier charg√© n'est pas une matrice de co-occurrence carr√©e valide. V√©rifiez le chemin fourni."
                )
                st.error(
                    "Le fichier charg√© n'est pas une matrice de co-occurrence carr√©e. Assurez-vous d'avoir pr√©calcul√© la matrice avec `utils/preprocess_ingredients_matrix.py` et que le chemin est `data/ingredients_cooccurrence_matrix.csv`."
                )
                st.stop()
            elif cooc_matrix.shape[0] > 500:
                _self.logger.warning(
                    f"‚ö†Ô∏è Matrice tr√®s grande ({cooc_matrix.shape}); ce n'est probablement pas le fichier pr√©calcul√© attendu."
                )

            # Normalisation l√©g√®re des labels (mais on conserve casse/minuscule existante)
            cooc_matrix.index = cooc_matrix.index.str.strip()
            cooc_matrix.columns = cooc_matrix.columns.str.strip()

            # V√©rifier sym√©trie des labels
            idx_set = set(cooc_matrix.index)
            col_set = set(cooc_matrix.columns)
            if idx_set != col_set:
                missing_in_cols = idx_set - col_set
                missing_in_idx = col_set - idx_set
                _self.logger.warning(
                    f"‚ö†Ô∏è Mismatch labels: rows_only={len(missing_in_cols)}, cols_only={len(missing_in_idx)}"
                )
                # Intersection pour carr√© coh√©rent
                common = sorted(idx_set & col_set)
                cooc_matrix = cooc_matrix.loc[common, common]
                _self.logger.info(
                    f"üîß Matrice r√©duite √† intersection commune: {cooc_matrix.shape}"
                )

            # Forcer colonnes = index si ordre diff√©rent
            if not (cooc_matrix.index.tolist() == cooc_matrix.columns.tolist()):
                _self.logger.warning("‚ö†Ô∏è R√©ordonnancement des colonnes pour correspondre √† l'index")
                cooc_matrix = cooc_matrix[cooc_matrix.index]

            # V√©rifier doublons
            if cooc_matrix.index.has_duplicates or cooc_matrix.columns.has_duplicates:
                _self.logger.warning("‚ö†Ô∏è Doublons d√©tect√©s dans labels; d√©duplication")
                # D√©duplication par agr√©gation (somme)
                cooc_matrix = (
                    cooc_matrix.groupby(cooc_matrix.index).sum()
                )
                cooc_matrix = cooc_matrix[cooc_matrix.index]  # r√©aligner colonnes
                _self.logger.info(
                    f"üîÅ Apr√®s d√©duplication: {cooc_matrix.shape}"
                )

            _self.logger.info(
                f"‚úÖ Matrice finalis√©e: {cooc_matrix.shape} | Sample: {cooc_matrix.index[:5].tolist()}"
            )

            if not _self.ingredients_list_path.exists():
                st.error(f"‚ùå Liste des ingr√©dients introuvable: {_self.ingredients_list_path}")
                st.stop()
                return None

            ingredients_list = pd.read_csv(_self.ingredients_list_path)
            ingredients_list['ingredient'] = ingredients_list['ingredient'].str.strip()
            _self.logger.info(
                f"‚úÖ Liste charg√©e: {len(ingredients_list)} ingr√©dients | Top 5: {ingredients_list.head()['ingredient'].tolist()}"
            )

            return cooc_matrix, ingredients_list

        except Exception as e:
            st.error(f"‚ùå Erreur de chargement: {e}")
            _self.logger.error(f"Failed to load precomputed matrix: {e}")
            st.stop()
            return None

    def render_sidebar(self) -> dict[str, int | bool]:
        """Affiche la sidebar avec les param√®tres de clustering.

        Returns:
            Dictionnaire contenant les param√®tres s√©lectionn√©s.
        """
        st.sidebar.header("üîß Param√®tres de Clustering")

        st.sidebar.info("üìä Matrice pr√©calcul√©e: 300 ingr√©dients")

        # Nombre d'ingr√©dients √† s√©lectionner
        n_ingredients = st.sidebar.slider(
            "Nombre d'ingr√©dients √† analyser",
            min_value=40,
            max_value=300,
            value=40,
            step=10,
            help="S√©lectionner les N ingr√©dients les plus fr√©quents depuis la matrice 300x300",
        )

        # Nombre de clusters
        n_clusters = st.sidebar.slider(
            "Nombre de clusters",
            min_value=3,
            max_value=20,
            value=4,
            step=1,
            help="Nombre de groupes d'ingr√©dients √† cr√©er avec K-means",
        )

        # Param√®tres t-SNE
        st.sidebar.subheader("üé® Visualisation t-SNE")
        tsne_perplexity = st.sidebar.slider(
            "Perplexit√©",
            min_value=5,
            max_value=50,
            value=30,
            step=5,
            help="Contr√¥le la densit√© des groupes (5=local, 50=global)",
        )

        # Bouton d'analyse
        analyze_button = st.sidebar.button("üöÄ Lancer l'analyse", type="primary")

        return {
            "n_ingredients": n_ingredients,
            "n_clusters": n_clusters,
            "tsne_perplexity": tsne_perplexity,
            "analyze_button": analyze_button,
        }

    def _select_top_ingredients(
        self, cooc_matrix: pd.DataFrame, ingredients_list: pd.DataFrame, n: int
    ) -> tuple[pd.DataFrame, list[str]]:
        """S√©lectionne robustement les N ingr√©dients les plus fr√©quents.

        Diagnostic d√©taill√©:
        - Taille liste vs matrice
        - Intersections
        - Fallback si mismatch complet (utilisation directe de l'index matrice)
        """
        matrix_index = list(cooc_matrix.index)
        matrix_cols = list(cooc_matrix.columns)

        # Logs de diagnostic
        self.logger.info(
            f"üîé Diagnostic s√©lection: matrix_index={len(matrix_index)}, matrix_cols={len(matrix_cols)}, list_rows={len(ingredients_list)}"
        )

        if set(matrix_index) != set(matrix_cols):
            self.logger.warning("‚ö†Ô∏è Les labels lignes/colonnes ne correspondent pas parfaitement.")

        list_ings = ingredients_list['ingredient'].tolist()
        inter_with_index = set(list_ings) & set(matrix_index)
        inter_with_cols = set(list_ings) & set(matrix_cols)
        self.logger.info(
            f"üîé Intersections: with_index={len(inter_with_index)}, with_cols={len(inter_with_cols)}"
        )

        if not inter_with_index:
            self.logger.error("‚ùå Aucune intersection entre la liste et l'index de la matrice. Fallback sur index brut.")
            # Fallback: prendre directement premiers n ingr√©dients de la matrice
            top_final = matrix_index[:n]
            sub_matrix = cooc_matrix.loc[top_final, top_final]
            self.logger.info(
                f"‚úÖ Fallback utilis√©: {len(top_final)} ingr√©dients | shape={sub_matrix.shape}"
            )
            return sub_matrix, top_final

        # Filtrage selon index (pas colonnes encore)
        filtered = ingredients_list[ingredients_list['ingredient'].isin(matrix_index)]
        top = filtered.nlargest(n, 'frequency')['ingredient'].tolist()

        # V√©rification colonnes
        top_valid = [ing for ing in top if ing in set(matrix_cols)]
        lost = set(top) - set(top_valid)
        if lost:
            self.logger.warning(
                f"‚ö†Ô∏è Ingr√©dients pr√©sents dans index mais absents des colonnes ignor√©s: {list(lost)[:8]}{'...' if len(lost)>8 else ''}"
            )

        top_final = top_valid[:n]
        if len(top_final) < n:
            self.logger.warning(
                f"‚ö†Ô∏è Seulement {len(top_final)}/{n} ingr√©dients disponibles apr√®s filtrage"
            )

        sub_matrix = cooc_matrix.reindex(index=top_final, columns=top_final)
        if sub_matrix.isna().any().any():
            self.logger.warning("‚ö†Ô∏è NaN d√©tect√©s dans sous-matrice; remplissage √† 0")
            sub_matrix = sub_matrix.fillna(0)

        self.logger.info(
            f"‚úÖ S√©lection finale: {len(top_final)} ingr√©dients | shape={sub_matrix.shape}"
        )
        return sub_matrix, top_final

    def _perform_clustering(self, matrix: pd.DataFrame, n_clusters: int) -> np.ndarray:
        """Effectue le clustering K-means sur la matrice.

        Args:
            matrix: Matrice de co-occurrence.
            n_clusters: Nombre de clusters.

        Returns:
            Array des labels de cluster.
        """
        self.logger.info(f"Performing K-means clustering with k={n_clusters}")

        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        clusters = kmeans.fit_predict(matrix.values)

        self.logger.info(f"Clustering completed: {len(set(clusters))} unique clusters")

        return clusters

    def _generate_tsne(
        self, matrix: pd.DataFrame, clusters: np.ndarray, perplexity: int
    ) -> dict:
        """G√©n√®re la visualisation t-SNE.

        Args:
            matrix: Matrice de co-occurrence.
            clusters: Labels de cluster.
            perplexity: Param√®tre de perplexit√©.

        Returns:
            Dict avec coordonn√©es x, y et m√©tadonn√©es.
        """
        self.logger.info(f"Generating t-SNE visualization with perplexity={perplexity}")

        try:
            # Ajuster la perplexit√© si n√©cessaire
            n_samples = matrix.shape[0]
            adjusted_perplexity = min(perplexity, n_samples - 1)

            if adjusted_perplexity != perplexity:
                self.logger.warning(
                    f"Perplexity adjusted from {perplexity} to {adjusted_perplexity} (n_samples={n_samples})"
                )

            # t-SNE
            tsne = TSNE(
                n_components=2,
                perplexity=adjusted_perplexity,
                random_state=42,
                max_iter=1000,
            )

            coords = tsne.fit_transform(matrix.values)

            return {
                "x_coords": coords[:, 0].tolist(),
                "y_coords": coords[:, 1].tolist(),
                "ingredient_names": matrix.index.tolist(),
                "cluster_labels": clusters.tolist(),
                "n_clusters": len(set(clusters)),
                "tsne_params": {
                    "perplexity": adjusted_perplexity,
                    "max_iter": 1000,
                    "random_state": 42,
                    "method": "tsne",
                },
            }

        except Exception as e:
            self.logger.error(f"t-SNE failed: {e}")
            return {"error": str(e)}

    def render_cooccurrence_analysis(
        self, ingredient_names: list[str], matrix: pd.DataFrame
    ) -> None:
        """Affiche l'analyse de co-occurrence interactive."""
        st.subheader("üîç Analyse de Co-occurrence")

        col1, col2 = st.columns(2)

        with col1:
            ing1 = st.selectbox("Premier ingr√©dient", options=ingredient_names, index=0)

        with col2:
            ing2 = st.selectbox(
                "Deuxi√®me ingr√©dient",
                options=ingredient_names,
                index=1 if len(ingredient_names) > 1 else 0,
            )

        if ing1 and ing2 and ing1 != ing2:
            try:
                score = matrix.at[ing1, ing2]
                max_score = matrix.values.max()
                avg_score = matrix.values[matrix.values > 0].mean()

                col_m1, col_m2, col_m3 = st.columns(3)

                with col_m1:
                    st.metric("Score", f"{score:.0f}", help="Nombre de recettes communes")

                with col_m2:
                    percentile = (score / max_score) * 100 if max_score > 0 else 0
                    st.metric("Percentile", f"{percentile:.1f}%")

                with col_m3:
                    ratio = score / avg_score if avg_score > 0 else 0
                    st.metric("vs Moyenne", f"{ratio:.1f}x")

                # Barre de progression
                if max_score > 0:
                    st.progress(score / max_score)

                # Interpr√©tation
                if score >= avg_score * 2:
                    st.success("üî• Combinaison tr√®s fr√©quente!")
                elif score >= avg_score:
                    st.info("‚úÖ Combinaison courante")
                elif score > 0:
                    st.warning("‚ö†Ô∏è Combinaison rare")
                else:
                    st.error("‚ùå Aucune co-occurrence")

            except Exception as e:
                st.warning(f"Erreur: {e}")

    def render_clusters(
        self, clusters: np.ndarray, ingredient_names: list[str], n_clusters: int
    ) -> None:
        """Affiche les clusters d'ingr√©dients."""
        st.subheader("üéØ Clusters d'Ingr√©dients")

        colors = ["üî¥", "üü†", "üü°", "üü¢", "üîµ", "üü£", "‚ö´", "‚ö™", "üü§", "üîò"]

        for cluster_id in range(n_clusters):
            cluster_ings = [
                ingredient_names[i]
                for i, c in enumerate(clusters)
                if c == cluster_id
            ]

            color = colors[cluster_id % len(colors)]

            with st.expander(
                f"{color} Cluster {cluster_id + 1} ({len(cluster_ings)} ingr√©dients)",
                expanded=cluster_id < 2,  # Expand first 2 clusters only
            ):
                cols = st.columns(4)
                for i, ing in enumerate(cluster_ings):
                    cols[i % 4].write(f"‚Ä¢ **{ing}**")

    def render_tsne_visualization(self, tsne_data: dict) -> None:
        """Affiche la visualisation t-SNE."""
        st.subheader("üé® Visualisation t-SNE 2D")

        if "error" in tsne_data:
            st.error(f"‚ùå Erreur t-SNE: {tsne_data['error']}")
            return

        # Cr√©er le graphique
        fig = go.Figure()

        colors = [
            "#FF6B6B",
            "#4ECDC4",
            "#45B7D1",
            "#96CEB4",
            "#FFEAA7",
            "#DDA0DD",
            "#98D8C8",
            "#F7DC6F",
            "#BB8FCE",
            "#85C1E9",
            "#F8B88B",
            "#FAA0A0",
            "#B0E57C",
            "#87CEEB",
            "#DDA0DD",
            "#F0E68C",
            "#FFB6C1",
            "#20B2AA",
            "#FF69B4",
            "#BA55D3",
        ]

        n_clusters = tsne_data["n_clusters"]

        for cluster_id in range(n_clusters):
            mask = [label == cluster_id for label in tsne_data["cluster_labels"]]
            cluster_x = [x for i, x in enumerate(tsne_data["x_coords"]) if mask[i]]
            cluster_y = [y for i, y in enumerate(tsne_data["y_coords"]) if mask[i]]
            cluster_names = [
                name for i, name in enumerate(tsne_data["ingredient_names"]) if mask[i]
            ]

            color = colors[cluster_id % len(colors)]

            fig.add_trace(
                go.Scatter(
                    x=cluster_x,
                    y=cluster_y,
                    mode="markers+text",
                    marker=dict(size=12, color=color, line=dict(width=2, color="white"), opacity=0.8),
                    text=cluster_names,
                    textposition="top center",
                    textfont=dict(size=10),
                    name=f"Cluster {cluster_id + 1}",
                    hovertemplate=f"<b>%{{text}}</b><br>Cluster: {cluster_id + 1}<extra></extra>",
                )
            )

        fig.update_layout(
            title="Visualisation t-SNE des Ingr√©dients",
            xaxis_title="Dimension 1",
            yaxis_title="Dimension 2",
            showlegend=True,
            height=600,
            hovermode="closest",
            plot_bgcolor="rgba(245,245,245,0.8)",
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        )

        st.plotly_chart(fig, use_container_width=True)

        with st.expander("‚ÑπÔ∏è √Ä propos de t-SNE"):
            st.markdown(
                """
            **t-SNE** r√©duit la dimensionnalit√© pour visualiser les similarit√©s entre ingr√©dients.
            
            - **Points proches** = ingr√©dients avec profils de co-occurrence similaires
            - **Couleurs** = clusters K-means
            - **Distance** = mesure de similarit√© culinaire
            
            **Param√®tres utilis√©s**:
            - Perplexit√©: {}
            - It√©rations: 1000
            - Seed: 42
            """.format(
                    tsne_data["tsne_params"]["perplexity"]
                )
            )

    def render_sidebar_statistics(
        self, clusters: np.ndarray, ingredient_names: list[str]
    ) -> None:
        """Affiche les statistiques dans la sidebar."""
        st.sidebar.markdown("---")
        st.sidebar.markdown("### üìä Statistiques")

        cluster_counts = pd.Series(clusters).value_counts().sort_index()

        st.sidebar.metric("Ingr√©dients analys√©s", len(ingredient_names))
        st.sidebar.metric("Clusters cr√©√©s", len(cluster_counts))

        # Graphique
        st.sidebar.markdown("**R√©partition:**")

        colors = [
            "#FF6B6B",
            "#4ECDC4",
            "#45B7D1",
            "#96CEB4",
            "#FFEAA7",
            "#DDA0DD",
            "#98D8C8",
            "#F7DC6F",
            "#BB8FCE",
            "#85C1E9",
        ]

        fig = go.Figure()

        for i, count in enumerate(cluster_counts):
            percentage = (count / len(ingredient_names)) * 100
            color = colors[i % len(colors)]

            fig.add_trace(
                go.Bar(
                    x=[count],
                    y=[f"C{i + 1}"],
                    orientation="h",
                    marker_color=color,
                    text=f"{count} ({percentage:.0f}%)",
                    textposition="outside",
                    showlegend=False,
                )
            )

        fig.update_layout(
            xaxis_title="Nombre",
            height=min(400, len(cluster_counts) * 40 + 100),
            margin=dict(l=10, r=10, t=10, b=10),
            font=dict(size=10),
        )

        st.sidebar.plotly_chart(fig, use_container_width=True)

    def _render_step_1_preprocessing(self) -> None:
        """Affiche l'√©tape 1 : Pr√©traitement NLP des ingr√©dients."""
        st.markdown("---")
        st.header("üìà √âTAPE 1 : Pr√©traitement NLP des ingr√©dients")

        st.markdown(
            """
        **Question :** Comment normaliser et regrouper les variantes d'un m√™me ingr√©dient ?

        Les recettes utilisent des descriptions vari√©es pour un m√™me ingr√©dient (ex: "sel", "gros sel",
        "sel de mer", "sel fin"). Le pr√©traitement NLP vise √† identifier et regrouper ces variantes
        pour cr√©er une repr√©sentation coh√©rente.

        **M√©trique :** Taux de r√©duction du nombre d'ingr√©dients uniques apr√®s normalisation.
        
        **üí° Note technique :** Cette √©tape a √©t√© **pr√©calcul√©e √† froid** lors de la g√©n√©ration de la 
        matrice 300√ó300 avec `utils/preprocess_ingredients_matrix.py`. Environ **~230,000 recettes** ont 
        √©t√© trait√©es pour extraire et normaliser les 300 ingr√©dients les plus fr√©quents.

        **M√©thodologie appliqu√©e :**
        - Normalisation : minuscules, suppression ponctuation, filtrage stop words
        - Regroupement : variantes lexicales fusionn√©es
        - R√©duction typique : ~70% des variantes √©limin√©es

        **üéØ R√©sultat :** Le pr√©traitement r√©duit significativement la redondance en identifiant
        les variantes linguistiques d'un m√™me ingr√©dient. Cette √©tape est cruciale pour obtenir une
        matrice de co-occurrence fiable et permet de concentrer l'analyse sur les v√©ritables patterns
        culinaires plut√¥t que sur les variations de nomenclature.
        """
        )

    def _render_step_2_cooccurrence(
        self, ingredient_names: list[str], matrix: pd.DataFrame
    ) -> None:
        """Affiche l'√©tape 2 : Cr√©ation de la matrice de co-occurrence."""
        st.markdown("---")
        st.header("üìà √âTAPE 2 : Matrice de co-occurrence")

        st.markdown(
            """
        **Objectif :** Quantifier la fr√©quence d'apparition conjointe de chaque paire d'ingr√©dients.

        La matrice de co-occurrence capture l'information fondamentale : combien de fois deux
        ingr√©dients apparaissent ensemble dans les recettes. Cette matrice sym√©trique constitue
        la base de notre analyse de similarit√©.

        **M√©thode :** Pour chaque recette, toutes les paires d'ingr√©dients pr√©sents sont comptabilis√©es.
        
        **üí° Note technique :** Cette matrice **300√ó300** a √©t√© **pr√©calcul√©e √† froid** sur l'ensemble 
        du corpus (~230,000 recettes). Vous s√©lectionnez dynamiquement un sous-ensemble (40-300 ingr√©dients) 
        de cette matrice pour votre analyse.
        """
        )

        # Statistiques de la matrice
        total_cooccurrences = int(matrix.values.sum() / 2)
        non_zero_pairs = int((matrix.values > 0).sum() / 2)
        matrix_size = len(ingredient_names)
        max_possible_pairs = matrix_size * (matrix_size - 1) / 2
        sparsity = (1 - non_zero_pairs / max_possible_pairs) * 100

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Dimension matrice", f"{matrix_size}√ó{matrix_size}")
        with col2:
            st.metric("Co-occurrences totales", f"{total_cooccurrences:,}")
        with col3:
            st.metric("Paires non-nulles", f"{non_zero_pairs:,}")
        with col4:
            st.metric(
                "Sparsit√©",
                f"{sparsity:.1f}%",
                help="Pourcentage de paires sans co-occurrence",
            )

        st.markdown("---")

        # Analyse interactive de co-occurrence
        self.render_cooccurrence_analysis(ingredient_names, matrix)

        st.markdown(
            """
        **üìä Ce que r√©v√®le la matrice :**

        La distribution des co-occurrences n'est pas uniforme. Certaines paires d'ingr√©dients
        apparaissent ensemble dans des milliers de recettes, r√©v√©lant des associations culinaires
        fortes.

        """
        )

    def _render_step_3_clustering(
        self, clusters: np.ndarray, ingredient_names: list[str], n_clusters: int
    ) -> None:
        """Affiche l'√©tape 3 : Clustering K-means."""
        st.markdown("---")
        st.header("üìà √âTAPE 3 : Clustering K-means")

        st.markdown(
            f"""
        **Objectif :** Regrouper automatiquement les ingr√©dients en {n_clusters} familles distinctes.

        L'algorithme K-means partitionne les ingr√©dients en fonction de leurs profils de co-occurrence.
        Deux ingr√©dients dans le m√™me cluster partagent des contextes d'utilisation similaires, m√™me
        s'ils ne co-occurrent pas directement.

        **M√©thode :** K-means avec k={n_clusters}, distance euclidienne sur les vecteurs de co-occurrence.
        """
        )

        # Statistiques des clusters
        cluster_counts = pd.Series(clusters).value_counts().sort_index()

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Nombre de clusters", n_clusters)
        with col2:
            avg_size = len(ingredient_names) / n_clusters
            st.metric("Taille moyenne", f"{avg_size:.1f} ingr√©dients")
        with col3:
            largest_cluster_size = cluster_counts.max()
            st.metric("Plus grand cluster", f"{largest_cluster_size} ingr√©dients")

        st.markdown("---")

        # Affichage des clusters
        self.render_clusters(clusters, ingredient_names, n_clusters)

        st.markdown(
            f"""
        **üéØ Interpr√©tation des clusters :**

        Les clusters arrivent √† r√©v√©ler des "famille culinaire" d'ingr√©dients. Ils peuvent √™tre :
        - **Ingr√©dients pour patisserie**
        - **Produits de recettes sal√©s**

        **Limite m√©thodologique** : Le choix de k={n_clusters} est param√©trique. Diff√©rentes valeurs
        de k r√©v√®lent des structures √† diff√©rentes granularit√©s.
        De plus, les clusters ont tendance √† ne pas √™tre de la m√™me taille car une masse d'ingr√©dient √† faible co-occurence se regrouppent ensemble.
        """
        )

    def _render_step_4_visualization(self, tsne_data: dict) -> None:
        """Affiche l'√©tape 4 : Visualisation t-SNE 2D."""
        st.markdown("---")
        st.header("üìà √âTAPE 4 : Visualisation t-SNE 2D")

        st.markdown(
            """
        **Objectif :** Projeter l'espace haute-dimensionnalit√© des co-occurrences en 2D pour exploration visuelle.

        La matrice de co-occurrence est un espace √† n dimensions (une par ingr√©dient). t-SNE
        (t-Distributed Stochastic Neighbor Embedding) r√©duit cette dimensionnalit√© √† 2D tout en
        pr√©servant les proximit√©s locales.

        **M√©thode :** t-SNE avec perplexit√© ajust√©e, optimisation par descente de gradient.
        """
        )

        # Visualisation t-SNE
        self.render_tsne_visualization(tsne_data)

        st.markdown(
            """
        **üîç Lecture de la visualisation :**

        - **Proximit√© spatiale** : Les ingr√©dients proches dans l'espace 2D ont des profils de
          co-occurrence similaires (utilis√©s dans des contextes culinaires similaires)
        - **Couleurs** : Chaque couleur repr√©sente un cluster K-means. La coh√©sion spatiale des
          couleurs valide la qualit√© du clustering
        - **Groupes isol√©s** : Les clusters bien s√©par√©s g√©ographiquement indiquent des familles
          culinaires distinctes

        **üí° Insights visuels :**

        La visualisation r√©v√®le souvent une structure non-lin√©aire de l'espace culinaire. Certains
        ingr√©dients "pont" peuvent se situer entre plusieurs clusters, refl√©tant leur polyvalence
        (ex: l'huile d'olive utilis√©e dans de multiples contextes, ou l'eau).

        **Validation du clustering** : Si les couleurs (clusters K-means) forment des groupes
        visuellement coh√©rents dans l'espace t-SNE, cela confirme que le clustering a captur√©
        des structures r√©elles plut√¥t qu'artificielles.

        **Limite de t-SNE** : La repr√©sentation 2D est approximative. Les distances absolues ne
        sont pas strictement pr√©serv√©es, seules les proximit√©s relatives comptent. Diff√©rentes
        ex√©cutions peuvent donner des configurations l√©g√®rement diff√©rentes (non-d√©terminisme).
        """
        )

    def _render_conclusion(
        self, ingredient_names: list[str], clusters: np.ndarray, n_clusters: int
    ) -> None:
        """Affiche la conclusion de l'analyse."""
        st.markdown("---")
        st.subheader("üìã Conclusion de l'analyse")

        # Calculer quelques statistiques finales
        cluster_counts = pd.Series(clusters).value_counts()
        largest_cluster = cluster_counts.max()
        smallest_cluster = cluster_counts.min()

        st.markdown(
            f"""
        ### Synth√®se des r√©sultats

        **1. Pr√©traitement NLP r√©ussi :** La normalisation automatique a permis de r√©duire
        significativement la redondance des variantes d'ingr√©dients, cr√©ant une base solide
        pour l'analyse.

        **2. Structure r√©v√©l√©e par la co-occurrence :** L'analyse de {len(ingredient_names)}
        ingr√©dients a r√©v√©l√© des patterns clairs d'association culinaire, confirmant que la
        cuisine n'est pas al√©atoire.

        **3. Clustering coh√©rent :** L'algorithme K-means a identifi√© {n_clusters} familles
        d'ingr√©dients distinctes, avec des tailles variant de {smallest_cluster} √† {largest_cluster}
        ingr√©dients. Ces clusters essaye de capturer des insight sur le co-usage des ingr√©dients.

        **4. Validation visuelle :** La projection t-SNE montre la structure des clusters et
        l'organisation de l'espace culinaire.

        ### Applications pratiques

        Ces r√©sultats peuvent √™tre utilis√©s pour :
        - **Syst√®mes de recommandation** : Sugg√©rer des ingr√©dients compl√©mentaires lors de la
          cr√©ation de recettes
        - **Analyse nutritionnelle** : Identifier les associations alimentaires courantes pour
          des √©tudes di√©t√©tiques, nottament en reliant les informations caloriques
        - **Cr√©ativit√© culinaire** : D√©couvrir des combinaisons innovantes en explorant les
          fronti√®res entre clusters
        - **D√©tection d'anomalies** : Identifier des recettes avec des combinaisons inhabituelles

        ### Limites et perspectives

        **Limites :**
        - La co-occurrence ne capture pas l'ordre ou les quantit√©s des ingr√©dients
        - Les ingr√©dients tr√®s rares ne sont pas repr√©sent√©s et ceux trop pr√©sent
        peuvent √™tre mal repr√©sent√©s

        **Perspectives d'am√©lioration :**
        - Clustering hi√©rarchique pour r√©v√©ler plusieurs niveaux de granularit√©
        - Int√©gration d'informations s√©mantiques (cat√©gories nutritionnelles, origines)
        - Mod√®les de recommandation bas√©s sur les embeddings d'ingr√©dients
        """
        )

    def run(self) -> None:
        """Point d'entr√©e principal de la page."""
        self.logger.info("Starting ingredients clustering analysis with precomputed matrix")

        # Introduction et User Story
        with st.expander("üéØ Objectifs et m√©thodologie de l'analyse", expanded=True):
            st.markdown(
                """
            ### Peut-on regrouper les ingr√©dients selon leurs usages culinaires ?

            Cette analyse explore les patterns de co-occurrence d'ingr√©dients dans les recettes pour
            identifier les associations culinaires naturelles. En analysant des milliers de recettes,
            nous r√©v√©lons les combinaisons d'ingr√©dients qui apparaissent fr√©quemment ensemble.

            **Questions centrales :** Quels ingr√©dients sont naturellement associ√©s ? Existe-t-il des
            familles d'ingr√©dients distinctes ? Comment les ingr√©dients se regroupent-ils en fonction
            de leurs profils d'utilisation ?

            **Approche :** 
            - **√âtapes 1-2 (pr√©calcul√©es √† froid)** : Analyse NLP des listes d'ingr√©dients et construction 
              d'une matrice de co-occurrence 300√ó300
            - **√âtapes 3-4 (temps r√©el)** : Clustering automatique par K-means et visualisation en 2D par t-SNE

            **Probl√©matique :** Dans un espace culinaire o√π des milliers d'ingr√©dients peuvent √™tre
            combin√©s, comment identifier automatiquement les groupes d'ingr√©dients qui partagent des
            contextes d'utilisation similaires ?
            
            **üí° Optimisation** : Les √©tapes 1-2 sont pr√©calcul√©es pour acc√©l√©rer l'analyse. Vous ajustez 
            le nombre d'ingr√©dients (40-300) et de clusters (3-20) en temps r√©el.
            """
            )

        # Sidebar
        params = self.render_sidebar()
        self.logger.debug(f"Parameters: {params}")

        # Charger la matrice pr√©calcul√©e
        data = self._load_cooccurrence_matrix()

        if data is None:
            return

        full_matrix, ingredients_list = data

        # V√©rifier si les param√®tres ont chang√©
        params_changed = False
        if "last_params" in st.session_state:
            last = st.session_state["last_params"]
            if (
                last["n_ingredients"] != params["n_ingredients"]
                or last["n_clusters"] != params["n_clusters"]
                or last["tsne_perplexity"] != params["tsne_perplexity"]
            ):
                params_changed = True

        # D√©cider si on lance l'analyse
        should_analyze = (
            params["analyze_button"]
            or "clusters" not in st.session_state
            or params_changed
        )

        if should_analyze:
            self.logger.info(
                f"Running analysis: n_ingredients={params['n_ingredients']}, n_clusters={params['n_clusters']}"
            )

            with st.spinner("Analyse en cours..."):
                # S√©lectionner les top N ingr√©dients
                matrix, ingredient_names = self._select_top_ingredients(
                    full_matrix, ingredients_list, params["n_ingredients"]
                )

                # Clustering
                clusters = self._perform_clustering(matrix, params["n_clusters"])

                # t-SNE
                tsne_data = self._generate_tsne(matrix, clusters, params["tsne_perplexity"])

                # Sauvegarder dans session
                st.session_state["matrix"] = matrix
                st.session_state["ingredient_names"] = ingredient_names
                st.session_state["clusters"] = clusters
                st.session_state["tsne_data"] = tsne_data
                st.session_state["last_params"] = params.copy()

        # Afficher les r√©sultats si disponibles
        if "clusters" in st.session_state:
            matrix = st.session_state["matrix"]
            ingredient_names = st.session_state["ingredient_names"]
            clusters = st.session_state["clusters"]
            tsne_data = st.session_state["tsne_data"]

            # M√©triques
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("üìä Matrice source", "300x300")
            with col2:
                st.metric("ü•ò Ingr√©dients analys√©s", f"{len(ingredient_names)}")
            with col3:
                st.metric("üéØ Clusters cr√©√©s", f"{params['n_clusters']}")

            # √âTAPES
            self._render_step_1_preprocessing()
            self._render_step_2_cooccurrence(ingredient_names, matrix)
            self._render_step_3_clustering(clusters, ingredient_names, params["n_clusters"])
            self._render_step_4_visualization(tsne_data)
            self._render_conclusion(ingredient_names, clusters, params["n_clusters"])

            # Statistiques sidebar
            self.render_sidebar_statistics(clusters, ingredient_names)

        # Footer
        st.markdown("---")
        st.caption(
            "üí° **Configuration** : Ajustez les param√®tres dans la sidebar pour explorer diff√©rentes configurations."
        )
